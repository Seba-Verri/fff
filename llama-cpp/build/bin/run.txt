./llama-cli -m tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf
./llama-cli -m tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf -p "TESTO"
./llama-cli -m tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf -f [file]

chmod +x llama-cli

wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf